INFO:root:cuda_device : 4
eos_m_token : EOS_M
beam_len_bonus : 0.5
mode : unknown
m : TSD
prev_z_method : separate
dataset : usr
seed : 0
vocab_size : 8000
embedding_size : 50
hidden_size : 50
lr : 0.003
lr_decay : 0.5
layer_num : 1
z_length : 16
max_ts : 50
early_stop_count : 5
cuda : True
degree_size : 1
split : (9, 1, 1)
root_dir : /Users/ahmedlokma/Desktop/user-simulator-master/sequicity_user
model_path : /Users/ahmedlokma/Desktop/user-simulator-master/sequicity_user/models/trainmodel.pkl
result_path : /Users/ahmedlokma/Desktop/user-simulator-master/sequicity_user/results/trainmodel.csv
vocab_path : /Users/ahmedlokma/Desktop/user-simulator-master/sequicity_user/vocab/vocab-trainmodel.pkl
data : /Users/ahmedlokma/Desktop/user-simulator-master/data/multiwoz-master/data/multi-woz/example2.json
entity : /Users/ahmedlokma/Desktop/user-simulator-master/data/multiwoz-master/data/multi-woz/example.json
db : /Users/ahmedlokma/Desktop/user-simulator-master/data/multiwoz-master/data/multi-woz/trainmodel.json
glove_path : ../sequicity/data/glove/glove.6B.50d.txt
batch_size : 32
dropout_rate : 0.5
epoch_num : 100
rl_epoch_num : 1
spv_proportion : 100
new_vocab : True
teacher_force : 100
beam_search : False
beam_size : 10
sampling : False
use_positional_embedding : False
unfrz_attn_epoch : 0
skip_unsup : False
truncated : False
pretrain : False

INFO:root:6865 known embedding. old mean: 0.000030 new mean -0.020280, old std 1.001408 new std 0.671768
INFO:root:loss:4.7823920249938965 pr_loss:0.00029758314485661685 m_loss:4.782094478607178 grad:0.5545923113822937
INFO:root:Traning time: 105.76984095573425
INFO:root:avg training loss in epoch 0 sup:6.590946
INFO:root:validation loss in epoch 0 sup:4.615497 unsup:0.000000
INFO:root:time for epoch 0: 137.907106
INFO:root:saving model...
INFO:root:loss:4.122627258300781 pr_loss:0.00268014008179307 m_loss:4.1199469566345215 grad:0.9180881977081299
INFO:root:Traning time: 217.68800592422485
INFO:root:avg training loss in epoch 1 sup:4.291824
INFO:root:validation loss in epoch 1 sup:4.281928 unsup:0.000000
INFO:root:time for epoch 1: 146.483670
INFO:root:saving model...
INFO:root:loss:3.761547088623047 pr_loss:0.001956631662324071 m_loss:3.7595903873443604 grad:0.6048305630683899
INFO:root:Traning time: 320.58644008636475
INFO:root:avg training loss in epoch 2 sup:3.899365
