INFO:root:cuda_device : 4
eos_m_token : EOS_M
beam_len_bonus : 0.5
mode : unknown
m : TSD
prev_z_method : separate
dataset : usr
seed : 0
vocab_size : 800
embedding_size : 50
hidden_size : 50
lr : 0.003
lr_decay : 0.5
layer_num : 1
z_length : 16
max_ts : 50
early_stop_count : 5
cuda : True
degree_size : 1
split : (9, 1, 1)
root_dir : /Users/ahmedlokma/Desktop/user-simulator-master/sequicity_user
model_path : /Users/ahmedlokma/Desktop/user-simulator-master/sequicity_user/models/trainmodel.pkl
result_path : /Users/ahmedlokma/Desktop/user-simulator-master/sequicity_user/results/trainmodel.csv
vocab_path : /Users/ahmedlokma/Desktop/user-simulator-master/sequicity_user/vocab/vocab-trainmodel.pkl
data : /Users/ahmedlokma/Desktop/user-simulator-master/data/multiwoz-master/data/multi-woz/act.json
entity : /Users/ahmedlokma/Desktop/user-simulator-master/data/multiwoz-master/data/multi-woz/trainmodelentity.json
db : /Users/ahmedlokma/Desktop/user-simulator-master/data/multiwoz-master/data/multi-woz/trainmodel.json
glove_path : ../sequicity/data/glove/glove.6B.50d.txt
batch_size : 32
dropout_rate : 0.5
epoch_num : 100
rl_epoch_num : 1
spv_proportion : 100
new_vocab : True
teacher_force : 100
beam_search : False
beam_size : 10
sampling : False
use_positional_embedding : False
unfrz_attn_epoch : 0
skip_unsup : False
truncated : False
pretrain : False

INFO:root:742 known embedding. old mean: -0.001683 new mean 0.039937, old std 0.996384 new std 0.689834
INFO:root:loss:13.487077713012695 pr_loss:6.621590614318848 m_loss:6.8654866218566895 grad:4.290520668029785
INFO:root:Traning time: 0.2252950668334961
INFO:root:avg training loss in epoch 0 sup:13.487078
